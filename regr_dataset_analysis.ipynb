{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from typing import Any, NamedTuple\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path('/home/kacper/Datasets/usg-kaggle/train/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = list(\n",
    "    (DATA_PATH / \"0\").rglob(\"lower_right_annotation.json\")\n",
    ")\n",
    "len(annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rule:\n",
    "    def compute(self, value: Any) -> bool:\n",
    "        raise NotImplementedError\n",
    "     \n",
    "    def __call__(self, value: Any) -> bool:\n",
    "        return self.compute(value)\n",
    "    \n",
    "    @staticmethod\n",
    "    def _from_lambda(a_lambda) -> \"Rule\":\n",
    "        rule = Rule()\n",
    "        rule.compute = a_lambda\n",
    "        return rule\n",
    "    \n",
    "    def or_(self, other: \"Rule\") -> \"Rule\":\n",
    "        return Rule._from_lambda(lambda value: self(value) or other(value))\n",
    "    \n",
    "    def and_(self, other: \"Rule\") -> \"Rule\":\n",
    "        return Rule._from_lambda(lambda value: self(value) and other(value))\n",
    "    \n",
    "    def not_(self) -> \"Rule\":\n",
    "        return Rule._from_lambda(lambda value: not self(value))\n",
    "    \n",
    "class Entry(NamedTuple):\n",
    "    attribute: str\n",
    "    value: float\n",
    "    \n",
    "class IsToShort(Rule):\n",
    "    def compute(self, value: Any) -> bool:\n",
    "        return len(value) <= 4\n",
    "    \n",
    "class HasTextInside(Rule):\n",
    "    def __init__(self, text: str):\n",
    "        self._text = text\n",
    "        \n",
    "    def compute(self, value: Any) -> bool:\n",
    "        return self._text in value\n",
    "    \n",
    "class CheckTexts:\n",
    "    def __init__(self, drop_condition: Rule):\n",
    "        self.drop_condition = drop_condition\n",
    "        \n",
    "    def __call__(self, texts: list) -> list:\n",
    "        new_data = []\n",
    "        for sample in texts:\n",
    "            if self.drop_condition.compute(sample):\n",
    "                continue\n",
    "            new_data.append(sample)\n",
    "        return new_data\n",
    "    \n",
    "class ExtractText:\n",
    "    def __call__(self, all_texts: list) -> list:\n",
    "        new_data = []\n",
    "        for sample in all_texts:\n",
    "            for subsample in sample.split('\\n'):\n",
    "                new_data.append(subsample)\n",
    "        return new_data\n",
    "    \n",
    "class SingleLineProcessor:\n",
    "    def transform_single_line(self, line: str) -> str:\n",
    "        raise NotImplementedError\n",
    "        \n",
    "class ConvertOto0(SingleLineProcessor):\n",
    "    def transform_single_line(self, line: str) -> str:\n",
    "        return line.replace('o', '0')\n",
    "    \n",
    "class RemoveL(SingleLineProcessor):\n",
    "    def transform_single_line(self, line: str) -> str:\n",
    "        return line.replace('l', '')\n",
    "    \n",
    "class RemoveUnits(SingleLineProcessor):\n",
    "    def transform_single_line(self, line: str) -> str:\n",
    "        return line.replace('kpa', '').replace('k', '').replace('mm', '')\n",
    "    \n",
    "class RemoveFinalForwardSlash(SingleLineProcessor):\n",
    "    def transform_single_line(self, line: str) -> str:\n",
    "        if line.endswith('/'):\n",
    "            return line[:-1]\n",
    "        return line\n",
    "    \n",
    "class RemoveInnerForwardSlash(SingleLineProcessor):\n",
    "    def transform_single_line(self, line: str) -> str:\n",
    "        return line.replace('/', '')\n",
    "    \n",
    "class Strip(SingleLineProcessor):\n",
    "    def transform_single_line(self, line: str) -> str:\n",
    "        return line.strip()\n",
    "    \n",
    "class ExtractEntry(SingleLineProcessor):\n",
    "    def transform_single_line(self, line: str) -> Entry:\n",
    "        components = line.split()\n",
    "        if len(components) > 2:\n",
    "            components = components[1:]\n",
    "        attribute, number_str = components\n",
    "        number = float(number_str)\n",
    "        return Entry(attribute, number)\n",
    "        \n",
    "class LinesProcessor:\n",
    "    def __init__(self, processors: list):\n",
    "        self._processors = processors\n",
    "        \n",
    "    def __call__(self, lines: list) -> list:\n",
    "        new_data = []\n",
    "        for line in lines:\n",
    "            for proc in self._processors:\n",
    "                line = proc.transform_single_line(line)\n",
    "            new_data.append(line)\n",
    "        return new_data\n",
    "    \n",
    "class EntriesSaver:\n",
    "    def __call__(self, entries: list, path: str):\n",
    "        a_dict = {\n",
    "            entry.attribute: entry.value\n",
    "            for entry in entries\n",
    "        }\n",
    "        \n",
    "        Path(path).write_text(json.dumps(a_dict))\n",
    "\n",
    "pre_text_clear = CheckTexts(\n",
    "    IsToShort().or_(HasTextInside(\"qbox\")).or_(HasTextInside(\"saturated\"))\n",
    ")\n",
    "\n",
    "additional_text_extractor = ExtractText()\n",
    "\n",
    "post_text_clear = CheckTexts(\n",
    "    IsToShort()\n",
    ")\n",
    "\n",
    "saver = EntriesSaver()\n",
    "\n",
    "\n",
    "text_processor = LinesProcessor([\n",
    "    ConvertOto0(),\n",
    "    RemoveUnits(),\n",
    "    RemoveFinalForwardSlash(),\n",
    "    RemoveInnerForwardSlash(),\n",
    "    RemoveL(),\n",
    "    Strip(),\n",
    "    ExtractEntry()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in annotations:\n",
    "    datum = json.loads(s.read_text())\n",
    "    ts = [d[\"text\"].lower() for d in datum]\n",
    "    ts = pre_text_clear(ts)\n",
    "    ts = additional_text_extractor(ts)\n",
    "    ts = post_text_clear(ts)\n",
    "    ts = text_processor(ts)\n",
    "    saver(ts, (s.parent / \"regression_ground_truth.json\").as_posix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
